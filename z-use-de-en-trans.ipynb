{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_gen import data_gen\n",
    "from model_seq2seq import Seq2SeqModel\n",
    "from model_generator import Generator\n",
    "from simple_loss_compute import SimpleLossCompute\n",
    "from run_epoch import run_epoch\n",
    "from print_examples import print_examples\n",
    "from iclib.core import init_seed, pt_init, pt_use_cuda, pt_device\n",
    "from iclib.print_info import set_print, toggle_print, p_hb, p_he, p_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "prc.init()\n",
    "#prc.init(use_gpu=False)\n",
    "print(\"CUDA:\", prc.use_cuda())\n",
    "print(\"DEVICE:\", prc.device())\n",
    "\n",
    "init_seed(42)\n",
    "\n",
    "V = 11\n",
    "E = 32\n",
    "H = 64\n",
    "L = 1\n",
    "dropout = 0.1\n",
    "\n",
    "S = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basis/linux/app/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqModel(V, V, E, E, H, L, dropout, Generator(H, V))\n",
    "if prc.use_cuda():\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = Path('.')/'models'\n",
    "mfile = mpath/'copy-task.pth'\n",
    "model.load_state_dict(torch.load(mfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = list(data_gen(num_words=V, batch_size=1, num_batches=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Example #3\n",
      "Src :  1 10 6 9 1 10 3 7 4\n",
      "Trg :  1 10 6 9 1 10 3 7 4\n",
      "Pred:  1 10 6 9 1 10 3 7 4\n",
      "\n",
      "Example #4\n",
      "Src :  3 5 3 7 5 9 7 2 4\n",
      "Trg :  3 5 3 7 5 9 7 2 4\n",
      "Pred:  3 5 3 7 5 9 7 2 4\n",
      "\n",
      "Example #5\n",
      "Src :  2 10 9 10 5 2 4 7 8\n",
      "Trg :  2 10 9 10 5 2 4 7 8\n",
      "Pred:  2 10 9 10 5 2 4 7 8\n",
      "\n",
      "Example #6\n",
      "Src :  1 4 2 8 4 2 6 6 10\n",
      "Trg :  1 4 2 8 4 2 6 6 10\n",
      "Pred:  1 4 2 8 4 2 6 6 10\n",
      "\n",
      "Example #7\n",
      "Src :  6 2 10 2 10 4 8 7 9\n",
      "Trg :  6 2 10 2 10 4 8 7 9\n",
      "Pred:  6 2 10 2 10 4 8 7 9\n",
      "\n",
      "Example #8\n",
      "Src :  5 2 5 8 10 9 9 1 9\n",
      "Trg :  5 2 5 8 10 9 9 1 9\n",
      "Pred:  5 2 5 8 10 9 9 1 9\n",
      "\n",
      "Example #9\n",
      "Src :  9 8 1 8 8 3 1 8 3\n",
      "Trg :  9 8 1 8 8 3 1 8 3\n",
      "Pred:  9 8 1 8 8 3 1 8 3\n",
      "\n",
      "Example #10\n",
      "Src :  1 5 10 7 10 9 7 9 8\n",
      "Trg :  1 5 10 7 10 9 7 9 8\n",
      "Pred:  1 5 10 7 10 9 7 9 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_examples(eval_data, model, n=100, max_len=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
